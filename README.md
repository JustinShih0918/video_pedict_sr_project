# Video Frame Interpolation and Super-Resolution Project

## Description

This project demonstrates video processing techniques including:
1.  **Optical Flow Estimation:** Calculates motion between video frames.
2.  **Frame Interpolation:** Generates an intermediate frame (frame1) between two input frames (frame0 and frame2) using optical flow and warping.
3.  **Flow Regularization:** Improves the quality of estimated optical flow fields.
4.  **Next Frame Prediction:** Predicts a subsequent frame (frame2) based on a previous frame (frame0) and their optical flow.
5.  **Super-Resolution:** Enhances the resolution of the generated intermediate frame.

The primary script `main_infer.py` orchestrates these processes.

## Features

*   Estimates optical flow using OpenCV's Farneback method.
*   Applies flow regularization to smooth and improve flow fields.
*   Warps frames based on optical flow to synthesize intermediate views.
*   Fuses warped frames to create a coherent interpolated frame.
*   Upscales the interpolated frame using a basic super-resolution technique (e.g., bicubic interpolation via `cv2.resize`).
*   Predicts a future frame and evaluates its quality against a ground truth.
*   Saves processed frames to an `output/` directory.
*   Computes PSNR and SSIM metrics for evaluation (if ground truth is available).

## Prerequisites

*   Python 3.x (tested with Python 3.9)
*   A virtual environment is recommended.

## Setup and Installation

1.  **Clone the repository (if applicable) or ensure you have the project files.**

2.  **Create and activate a virtual environment:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```
    *(On Windows, use `venv\Scripts\activate`)*

3.  **Install the required Python packages:**
    ```bash
    pip install -r requirements.txt
    ```

## Usage

1.  **Prepare Input Data:**
    *   Place your input frames (e.g., `frame0.png`, `frame2.png`, and optionally `frame1.png` for evaluation) in a directory. The script currently expects them in `data/public/`. You can modify the paths in `main_infer.py` if needed.

2.  **Run the main script:**
    ```bash
    python main_infer.py
    ```

3.  **Deactivate the virtual environment when done:**
    ```bash
    deactivate
    ```

## Output

The script will generate the following files in the `output/` directory:
*   `frame1_pred_regularized.png`: The super-resolved interpolated frame (predicted frame1).
*   `predicted_frame2_from_frame0.png`: The predicted frame2, generated by warping frame0 with the regularized flow.
Debug messages and PSNR/SSIM scores (if applicable) will be printed to the console.

## Project Structure

*   `main_infer.py`: The main script to run the inference pipeline.
*   `requirements.txt`: Lists Python package dependencies.
*   `models/`: Directory containing the core processing modules:
    *   `__init__.py`: Makes `models` a Python package.
    *   `optical_flow.py`: Contains `estimate_flow` for optical flow calculation.
    *   `fusion.py`: Contains `warp_frame` and `fuse_frames` for frame interpolation.
    *   `super_resolution.py`: Contains `upscale` for increasing frame resolution.
    *   `flow_regularization.py`: Contains `regularize_flow_field` for improving flow quality.
*   `utils/`: Directory for utility functions:
    *   `__init__.py`: Makes `utils` a Python package.
    *   `metrics.py`: Contains `compute_psnr_ssim` for evaluating image quality.
*   `data/`: (Assumed) Directory for input data.
    *   `public/`: (Assumed) Sub-directory for specific datasets like `frame0.png`, `frame1.png`, `frame2.png`.
*   `output/`: Directory where processed images are saved.
*   `venv/`: (If created) Python virtual environment directory.

## Potential Improvements / Future Work

*   Implement more advanced optical flow algorithms (e.g., PWC-Net, RAFT).
*   Explore more sophisticated super-resolution models (e.g., ESRGAN, SRCNN).
*   Improve flow regularization techniques.
*   Add support for processing entire video sequences instead of just pairs/triplets of frames.
*   Implement more robust occlusion handling in the warping and fusion steps.
*   Add command-line arguments for input paths, output paths, and hyperparameters.
