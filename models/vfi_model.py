# -*- coding: utf-8 -*-
"""testing (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i2qAsDrDZX6PLe95f6PmCHMT2CinbBbZ
"""

# âœ… Step 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os
import glob
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
import cv2
from tqdm import tqdm
import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF
import torch.nn as nn
import torch.nn.functional as F
from skimage.metrics import structural_similarity as ssim_func
from skimage.metrics import peak_signal_noise_ratio as psnr_func
!pip install torch torchvision

"""# âœ… Step 2: Unzip the dataset"""

# Step 2: Unzip dataset if not exists
zip_path = '/content/drive/MyDrive/topic4_release.zip'
extract_path = '/content/'
if not os.path.exists(os.path.join(extract_path, 'topic4_release')):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

# Step 3: Collect im1, im2, im3, im5, im6, im7 paths + gt (im4)
def collect_paths_v2(res_type='High_Resolution'):
    base_path = f'/content/train/{res_type}'
    video_folders = sorted(glob.glob(f'{base_path}/*/*'))
    path_list = []
    for folder in video_folders:
        frame_paths = [os.path.join(folder, f'im{i}.png') for i in range(1, 8)]
        if not all(os.path.exists(p) for p in frame_paths):
            continue
        # inputs: im1,2,3,5,6,7 ; gt: im4
        inputs = [frame_paths[i] for i in (0,1,2,4,5,6)]
        gt = frame_paths[3]
        path_list.append((inputs, gt))
    return path_list

# Step 4: Optical flow function (im3 -> im5)
def compute_flow(f0, f1):
    gray0 = cv2.cvtColor(f0, cv2.COLOR_BGR2GRAY)
    gray1 = cv2.cvtColor(f1, cv2.COLOR_BGR2GRAY)
    flow = cv2.calcOpticalFlowFarneback(gray0, gray1,
                                        None, 0.5, 3, 15, 3, 5, 1.2, 0)
    return flow

# Step 5: Prepare dataset class with flow cache
image_size = (256, 448)  # H, W
flow_cache_dir = '/content/flow_cache_updated'
os.makedirs(flow_cache_dir, exist_ok=True)

class InterpolationDatasetWithFlowCache(Dataset):
    def __init__(self, cached_list):
        self.cached = cached_list
        self.H, self.W = image_size
        self.transform = transforms.Compose([
            transforms.Resize((self.H, self.W)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.cached)

    def __getitem__(self, idx):
        inputs_paths, gt_path, flow_path = self.cached[idx]

        # è®€6å¼µå½±æ ¼ï¼ˆim1,2,3,5,6,7ï¼‰
        frames = []
        for p in inputs_paths:
            img = Image.open(p).convert('RGB')
            frames.append(self.transform(img))  # (3,H,W)

        # è®€ flow ä¸¦æ­£è¦åŒ–ã€resize
        flow = np.load(flow_path)  # shape: (H_org,W_org,2)
        flow_x = flow[...,0] / (flow.shape[1] - 1)
        flow_y = flow[...,1] / (flow.shape[0] - 1)
        flow_norm = np.stack([flow_x, flow_y], axis=-1)
        flow_resized = cv2.resize(flow_norm, (self.W, self.H), interpolation=cv2.INTER_LINEAR)
        flow_tensor = torch.from_numpy(flow_resized).permute(2,0,1).float()

        # æ‹¼æ¥ (6*3 + 2) = 20 é€šé“
        input_tensor = torch.cat(frames + [flow_tensor], dim=0)

        # è®€ GT ä¸¦ resizeã€ToTensor
        gt = Image.open(gt_path).convert('RGB')
        gt = transforms.Resize((self.H, self.W))(gt)
        gt = transforms.ToTensor()(gt)

        return input_tensor, gt

# Step 6: Preprocess and cache flow
def preprocess_and_cache_flow(path_list):
    cached = []
    for inputs, gt_path in tqdm(path_list):
        im3_path, im5_path = inputs[2], inputs[3]
        name3 = os.path.splitext(os.path.basename(im3_path))[0]
        name5 = os.path.splitext(os.path.basename(im5_path))[0]
        flow_file = os.path.join(flow_cache_dir, f"{name3}_{name5}.npy")

        if not os.path.exists(flow_file):
            img3 = cv2.imread(im3_path)
            img5 = cv2.imread(im5_path)
            if img3 is None or img5 is None:
                continue
            flow = compute_flow(img3, img5)
            np.save(flow_file, flow)

        cached.append((inputs, gt_path, flow_file))
    return cached

# Step 6: Preprocess and cache flow
# æŠ“ Low_Resolution è·¯å¾‘ï¼ˆå–å‰2000ç­†ï¼‰
high_paths = collect_paths_v2('High_Resolution')[:3000]
low_paths = collect_paths_v2('Low_Resolution')[:3000]

# å…©çµ„è·¯å¾‘ä¸€èµ· preprocess cache flow
cached_high = preprocess_and_cache_flow(high_paths)
cached_low = preprocess_and_cache_flow(low_paths)

# åˆä½µé«˜ä½è§£æåº¦è³‡æ–™é›†
cached_all = cached_high + cached_low

# å»ºç«‹ Dataset èˆ‡ Dataloader
dataset_all = InterpolationDatasetWithFlowCache(cached_all)
dataloader = DataLoader(dataset_all, batch_size=8, shuffle=True, num_workers=2)

class ImprovedInterpNet(nn.Module):
    def __init__(self, in_ch=20):
        super().__init__()
        # Encoder
        self.enc1 = nn.Sequential(
            nn.Conv2d(in_ch, 64, 3, padding=1), nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU()
        )
        self.pool1 = nn.MaxPool2d(2)

        self.enc2 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU()
        )
        self.pool2 = nn.MaxPool2d(2)

        self.bottleneck = nn.Sequential(
            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),
            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU()
        )

        # Decoder
        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec2 = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU()
        )

        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec1 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU()
        )

        # Output
        self.out_conv = nn.Conv2d(64, 3, 1)
        self.final_act = nn.Sigmoid()

    def forward(self, x):
        # Encoder
        x1 = self.enc1(x)  # (B,64,H,W)
        x2 = self.enc2(self.pool1(x1))  # (B,128,H/2,W/2)
        x3 = self.bottleneck(self.pool2(x2))  # (B,256,H/4,W/4)

        # Decoder
        x_up2 = self.up2(x3)  # (B,128,H/2,W/2)
        x_dec2 = self.dec2(torch.cat([x_up2, x2], dim=1))

        x_up1 = self.up1(x_dec2)  # (B,64,H,W)
        x_dec1 = self.dec1(torch.cat([x_up1, x1], dim=1))

        out = self.out_conv(x_dec1)
        return self.final_act(out)

pip install pytorch-msssim

print(len(dataloader))

def motion_weighted_loss(preds, targets, flows, base_loss):
    motion_mag = torch.norm(flows, dim=1, keepdim=True)  # shape: [B,1,H,W]
    weights = torch.tanh(motion_mag * 10) + 1.0  # [1,2] ç¯„åœå…§çš„æ¬Šé‡
    loss = base_loss(preds, targets)
    if isinstance(loss, torch.Tensor) and loss.shape == preds.shape:
        loss = (loss * weights).mean()
    return loss

def combined_loss(preds, targets, flows):
    l1 = F.l1_loss(preds, targets, reduction='none')
    ssim_comp = (1 - ssim_loss(preds, targets))  # scalar
    return motion_weighted_loss(preds, targets, flows, l1) * 0.8 + ssim_comp * 0.2

# Step 10: Train
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = ImprovedInterpNet().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
# base loss å¯ä»¥é¸ L1 æˆ– SSIMï¼ˆå»ºè­° L1 å…ˆæ¸¬ï¼‰
base_loss = torch.nn.L1Loss(reduction='none')  # æ³¨æ„ä¸€å®šè¦ reduction='none'

epochs = 15

for epoch in range(epochs):
    model.train()
    total_loss = 0
    for inputs, targets in dataloader:
        inputs, targets = inputs.to(device), targets.to(device)

        preds = model(inputs)

        # å¾ inputs ä¸­å–å‡ºæœ€å¾Œå…©å€‹ channel ç•¶ flow
        flows = inputs[:, -2:, :, :]  # shape: [B,2,H,W]

        # ä½¿ç”¨ motion åŠ æ¬Š loss
        loss = motion_weighted_loss(preds, targets, flows, base_loss)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1}/{epochs} - Loss: {total_loss / len(dataloader):.4f}")

torch.save(model.state_dict(), "/content/drive/MyDrive/final_model.pth")

# Step 12: PSNR & SSIM computation
def compute_ssim(img1, img2):
    img1_np = img1.permute(1, 2, 0).cpu().numpy()
    img2_np = img2.permute(1, 2, 0).cpu().numpy()
    return ssim_func(img1_np, img2_np, data_range=1.0, channel_axis=2)

def compute_psnr(img1, img2):
    img1_np = img1.permute(1, 2, 0).cpu().numpy()
    img2_np = img2.permute(1, 2, 0).cpu().numpy()
    return psnr_func(img1_np, img2_np, data_range=1.0)

# Step 13: Evaluate model on dataloader
model.eval()
ssim_scores = []
psnr_scores = []

with torch.no_grad():
    for inputs, targets in dataloader:
        inputs = inputs.to(device)
        targets = targets.to(device)
        preds = model(inputs)

        for pred, gt in zip(preds, targets):
            psnr = compute_psnr(pred, gt)
            ssim = compute_ssim(pred, gt)
            psnr_scores.append(psnr)
            ssim_scores.append(ssim)

avg_psnr = sum(psnr_scores) / len(psnr_scores)
avg_ssim = sum(ssim_scores) / len(ssim_scores)

print(f"\nâœ… Evaluation Finished:")
print(f"ğŸ“ˆ Average PSNR: {avg_psnr:.2f}")
print(f"ğŸ“ˆ Average SSIM: {avg_ssim:.4f}")

# Step 14: Helper function for loading & preprocessing image (used in inference)
def load_and_preprocess_image(path):
    img = Image.open(path).convert('RGB')
    img = transforms.Resize(image_size)(img)
    img = transforms.ToTensor()(img)
    return img

import torch.nn.functional as F
import torchvision.transforms.functional as TF
import matplotlib.pyplot as plt
import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
from torchvision.transforms import GaussianBlur

def apply_edge_enhancement(tensor_img, amount=1.5, radius=1, saturation_scale=1.2):
    """
    åœ¨ LAB ç©ºé—´å¯¹äº®åº¦è¿›è¡Œé”åŒ–ï¼Œå¢å¼ºé¢œè‰²å¯¹æ¯”ã€‚
    tensor_img: è¾“å…¥ Tensor (3, H, W)ï¼ŒèŒƒå›´[0,1]
    amount: é”åŒ–å¼ºåº¦
    radius: é«˜æ–¯æ¨¡ç³ŠåŠå¾„
    saturation_scale: é¥±å’Œåº¦æ”¾å¤§å€æ•°
    """

    # Tensor -> PIL -> NumPy RGB
    img_np = TF.to_pil_image(tensor_img)
    img_rgb = np.array(img_np)

    # è½¬åˆ° BGR (OpenCV é»˜è®¤)
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

    # è½¬ LAB
    img_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB).astype(np.float32)

    # L é€šé“é”åŒ–ï¼ˆUnsharp Maskï¼‰
    L = img_lab[:, :, 0]
    blurred = cv2.GaussianBlur(L, (2 * radius + 1, 2 * radius + 1), 0)
    L_sharp = cv2.addWeighted(L, 1 + amount, blurred, -amount, 0)
    L_sharp = np.clip(L_sharp, 0, 255)

    img_lab[:, :, 0] = L_sharp

    # é¥±å’Œåº¦å¢å¼º (a,bé€šé“)
    a = img_lab[:, :, 1] - 128
    b = img_lab[:, :, 2] - 128

    a = np.clip(a * saturation_scale, -128, 127)
    b = np.clip(b * saturation_scale, -128, 127)

    img_lab[:, :, 1] = a + 128
    img_lab[:, :, 2] = b + 128

    # LAB -> BGR -> RGB
    img_bgr = cv2.cvtColor(img_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

    # è½¬å› Tensor
    enhanced_tensor = TF.to_tensor(img_rgb).to(tensor_img.device).clamp(0, 1)

    return enhanced_tensor


def interpolate_and_evaluate_full6(im_paths, gt_path, model):
    # 1. è®€å–å…­å¼µå½±åƒä¸¦è½‰æˆ Tensor
    frames = [load_and_preprocess_image(p) for p in im_paths]

    # 2. Optical Flowï¼šä½¿ç”¨ im3 å’Œ im5
    img3 = cv2.imread(im_paths[2])
    img5 = cv2.imread(im_paths[3])
    if img3 is None or img5 is None:
        raise ValueError("âŒ im3 æˆ– im5 è®€å–å¤±æ•—")

    flow = compute_flow(img3, img5)
    flow_x = flow[..., 0] / (flow.shape[1] - 1)
    flow_y = flow[..., 1] / (flow.shape[0] - 1)
    flow_norm = np.stack([flow_x, flow_y], axis=-1)
    flow_resized = cv2.resize(flow_norm, (448, 256), interpolation=cv2.INTER_LINEAR)
    flow_tensor = torch.tensor(flow_resized).permute(2, 0, 1).float()

    # 3. æ¨¡å‹è¼¸å…¥
    input_tensor = torch.cat(frames + [flow_tensor], dim=0).unsqueeze(0).to(device)  # (1, 20, 256, 448)

    # 4. Ground Truthï¼Œbicubic æ’å€¼åˆ° 2x å°ºå¯¸
    gt_tensor = load_and_preprocess_image(gt_path)
    gt_tensor = F.interpolate(gt_tensor.unsqueeze(0), scale_factor=2, mode='bicubic', align_corners=False)[0]  # âœ… modified

    # 5. æ¨¡å‹é æ¸¬ + bicubic æ’å€¼
    model.eval()
    with torch.no_grad():
        output = model(input_tensor)  # (1, 3, 256, 448)
        output_upsampled = F.interpolate(output, scale_factor=2, mode='bicubic', align_corners=False)  # âœ… modified
        pred = output_upsampled[0].cpu()  # (3, 512, 896)

    # âœ… Edge Filtering å¢å¼·
    pred = apply_edge_enhancement(pred)  # âœ… added

    # 6. æ®˜å·®èª¤å·®åœ–
    residual = torch.abs(gt_tensor - pred).clamp(0, 1)

    # 7. è©•ä¼° PSNR / SSIM
    psnr = compute_psnr(pred, gt_tensor)
    ssim = compute_ssim(pred, gt_tensor)

    # 8. é¡¯ç¤ºçµæœ
    plt.figure(figsize=(15, 4))
    plt.subplot(1, 3, 1)
    plt.imshow(TF.to_pil_image(pred))
    plt.title("ğŸ”® Interpolated + Edge Enhancement")
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(TF.to_pil_image(gt_tensor))
    plt.title("ğŸ¯ Ground Truth (Upsampled)")
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(TF.to_pil_image(residual))
    plt.title("ğŸ“‰ Residual")
    plt.axis('off')

    plt.show()

    print(f"ğŸ“ˆ PSNR: {psnr:.2f}")
    print(f"ğŸ“ˆ SSIM: {ssim:.4f}")

    return pred, psnr, ssim, residual

import os
from glob import glob

base_path = '/content/public_test_set/'

# æ‰¾å‡ºæ‰€æœ‰åºåˆ—è·¯å¾„ï¼Œä¾‹å¦‚ 00071/0117
all_sequences = glob(os.path.join(base_path, '00071', '*'))

for seq_path in all_sequences:
    input_imgs = [os.path.join(seq_path, f'im{i}.png') for i in [1, 2, 3, 5, 6, 7]]
    gt_img = os.path.join(seq_path, 'im4.png')

    # è°ƒç”¨æ¨¡å‹æµ‹è¯•å‡½æ•°
    pred_frame, psnr, ssim, residual = interpolate_and_evaluate_full6(input_imgs, gt_img, model)

    print(f"çµæœ - åºåˆ—: {seq_path}")
    print(f"PSNR: {psnr:.2f}, SSIM: {ssim:.4f}")