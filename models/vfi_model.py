# -*- coding: utf-8 -*-
"""testing (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i2qAsDrDZX6PLe95f6PmCHMT2CinbBbZ
"""

# ✅ Step 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os
import glob
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
import cv2
from tqdm import tqdm
import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF
import torch.nn as nn
import torch.nn.functional as F
from skimage.metrics import structural_similarity as ssim_func
from skimage.metrics import peak_signal_noise_ratio as psnr_func
!pip install torch torchvision

"""# ✅ Step 2: Unzip the dataset"""

# Step 2: Unzip dataset if not exists
zip_path = '/content/drive/MyDrive/topic4_release.zip'
extract_path = '/content/'
if not os.path.exists(os.path.join(extract_path, 'topic4_release')):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

# Step 3: Collect im1, im2, im3, im5, im6, im7 paths + gt (im4)
def collect_paths_v2(res_type='High_Resolution'):
    base_path = f'/content/train/{res_type}'
    video_folders = sorted(glob.glob(f'{base_path}/*/*'))
    path_list = []
    for folder in video_folders:
        frame_paths = [os.path.join(folder, f'im{i}.png') for i in range(1, 8)]
        if not all(os.path.exists(p) for p in frame_paths):
            continue
        # inputs: im1,2,3,5,6,7 ; gt: im4
        inputs = [frame_paths[i] for i in (0,1,2,4,5,6)]
        gt = frame_paths[3]
        path_list.append((inputs, gt))
    return path_list

# Step 4: Optical flow function (im3 -> im5)
def compute_flow(f0, f1):
    gray0 = cv2.cvtColor(f0, cv2.COLOR_BGR2GRAY)
    gray1 = cv2.cvtColor(f1, cv2.COLOR_BGR2GRAY)
    flow = cv2.calcOpticalFlowFarneback(gray0, gray1,
                                        None, 0.5, 3, 15, 3, 5, 1.2, 0)
    return flow

# Step 5: Prepare dataset class with flow cache
image_size = (256, 448)  # H, W
flow_cache_dir = '/content/flow_cache_updated'
os.makedirs(flow_cache_dir, exist_ok=True)

class InterpolationDatasetWithFlowCache(Dataset):
    def __init__(self, cached_list):
        self.cached = cached_list
        self.H, self.W = image_size
        self.transform = transforms.Compose([
            transforms.Resize((self.H, self.W)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.cached)

    def __getitem__(self, idx):
        inputs_paths, gt_path, flow_path = self.cached[idx]

        # 讀6張影格（im1,2,3,5,6,7）
        frames = []
        for p in inputs_paths:
            img = Image.open(p).convert('RGB')
            frames.append(self.transform(img))  # (3,H,W)

        # 讀 flow 並正規化、resize
        flow = np.load(flow_path)  # shape: (H_org,W_org,2)
        flow_x = flow[...,0] / (flow.shape[1] - 1)
        flow_y = flow[...,1] / (flow.shape[0] - 1)
        flow_norm = np.stack([flow_x, flow_y], axis=-1)
        flow_resized = cv2.resize(flow_norm, (self.W, self.H), interpolation=cv2.INTER_LINEAR)
        flow_tensor = torch.from_numpy(flow_resized).permute(2,0,1).float()

        # 拼接 (6*3 + 2) = 20 通道
        input_tensor = torch.cat(frames + [flow_tensor], dim=0)

        # 讀 GT 並 resize、ToTensor
        gt = Image.open(gt_path).convert('RGB')
        gt = transforms.Resize((self.H, self.W))(gt)
        gt = transforms.ToTensor()(gt)

        return input_tensor, gt

# Step 6: Preprocess and cache flow
def preprocess_and_cache_flow(path_list):
    cached = []
    for inputs, gt_path in tqdm(path_list):
        im3_path, im5_path = inputs[2], inputs[3]
        name3 = os.path.splitext(os.path.basename(im3_path))[0]
        name5 = os.path.splitext(os.path.basename(im5_path))[0]
        flow_file = os.path.join(flow_cache_dir, f"{name3}_{name5}.npy")

        if not os.path.exists(flow_file):
            img3 = cv2.imread(im3_path)
            img5 = cv2.imread(im5_path)
            if img3 is None or img5 is None:
                continue
            flow = compute_flow(img3, img5)
            np.save(flow_file, flow)

        cached.append((inputs, gt_path, flow_file))
    return cached

# Step 6: Preprocess and cache flow
# 抓 Low_Resolution 路徑（取前2000筆）
high_paths = collect_paths_v2('High_Resolution')[:3000]
low_paths = collect_paths_v2('Low_Resolution')[:3000]

# 兩組路徑一起 preprocess cache flow
cached_high = preprocess_and_cache_flow(high_paths)
cached_low = preprocess_and_cache_flow(low_paths)

# 合併高低解析度資料集
cached_all = cached_high + cached_low

# 建立 Dataset 與 Dataloader
dataset_all = InterpolationDatasetWithFlowCache(cached_all)
dataloader = DataLoader(dataset_all, batch_size=8, shuffle=True, num_workers=2)

class ImprovedInterpNet(nn.Module):
    def __init__(self, in_ch=20):
        super().__init__()
        # Encoder
        self.enc1 = nn.Sequential(
            nn.Conv2d(in_ch, 64, 3, padding=1), nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU()
        )
        self.pool1 = nn.MaxPool2d(2)

        self.enc2 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU()
        )
        self.pool2 = nn.MaxPool2d(2)

        self.bottleneck = nn.Sequential(
            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),
            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU()
        )

        # Decoder
        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec2 = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU()
        )

        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec1 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU()
        )

        # Output
        self.out_conv = nn.Conv2d(64, 3, 1)
        self.final_act = nn.Sigmoid()

    def forward(self, x):
        # Encoder
        x1 = self.enc1(x)  # (B,64,H,W)
        x2 = self.enc2(self.pool1(x1))  # (B,128,H/2,W/2)
        x3 = self.bottleneck(self.pool2(x2))  # (B,256,H/4,W/4)

        # Decoder
        x_up2 = self.up2(x3)  # (B,128,H/2,W/2)
        x_dec2 = self.dec2(torch.cat([x_up2, x2], dim=1))

        x_up1 = self.up1(x_dec2)  # (B,64,H,W)
        x_dec1 = self.dec1(torch.cat([x_up1, x1], dim=1))

        out = self.out_conv(x_dec1)
        return self.final_act(out)

pip install pytorch-msssim

print(len(dataloader))

def motion_weighted_loss(preds, targets, flows, base_loss):
    motion_mag = torch.norm(flows, dim=1, keepdim=True)  # shape: [B,1,H,W]
    weights = torch.tanh(motion_mag * 10) + 1.0  # [1,2] 範圍內的權重
    loss = base_loss(preds, targets)
    if isinstance(loss, torch.Tensor) and loss.shape == preds.shape:
        loss = (loss * weights).mean()
    return loss

def combined_loss(preds, targets, flows):
    l1 = F.l1_loss(preds, targets, reduction='none')
    ssim_comp = (1 - ssim_loss(preds, targets))  # scalar
    return motion_weighted_loss(preds, targets, flows, l1) * 0.8 + ssim_comp * 0.2

# Step 10: Train
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = ImprovedInterpNet().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
# base loss 可以選 L1 或 SSIM（建議 L1 先測）
base_loss = torch.nn.L1Loss(reduction='none')  # 注意一定要 reduction='none'

epochs = 15

for epoch in range(epochs):
    model.train()
    total_loss = 0
    for inputs, targets in dataloader:
        inputs, targets = inputs.to(device), targets.to(device)

        preds = model(inputs)

        # 從 inputs 中取出最後兩個 channel 當 flow
        flows = inputs[:, -2:, :, :]  # shape: [B,2,H,W]

        # 使用 motion 加權 loss
        loss = motion_weighted_loss(preds, targets, flows, base_loss)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1}/{epochs} - Loss: {total_loss / len(dataloader):.4f}")

torch.save(model.state_dict(), "/content/drive/MyDrive/final_model.pth")

# Step 12: PSNR & SSIM computation
def compute_ssim(img1, img2):
    img1_np = img1.permute(1, 2, 0).cpu().numpy()
    img2_np = img2.permute(1, 2, 0).cpu().numpy()
    return ssim_func(img1_np, img2_np, data_range=1.0, channel_axis=2)

def compute_psnr(img1, img2):
    img1_np = img1.permute(1, 2, 0).cpu().numpy()
    img2_np = img2.permute(1, 2, 0).cpu().numpy()
    return psnr_func(img1_np, img2_np, data_range=1.0)

# Step 13: Evaluate model on dataloader
model.eval()
ssim_scores = []
psnr_scores = []

with torch.no_grad():
    for inputs, targets in dataloader:
        inputs = inputs.to(device)
        targets = targets.to(device)
        preds = model(inputs)

        for pred, gt in zip(preds, targets):
            psnr = compute_psnr(pred, gt)
            ssim = compute_ssim(pred, gt)
            psnr_scores.append(psnr)
            ssim_scores.append(ssim)

avg_psnr = sum(psnr_scores) / len(psnr_scores)
avg_ssim = sum(ssim_scores) / len(ssim_scores)

print(f"\n✅ Evaluation Finished:")
print(f"📈 Average PSNR: {avg_psnr:.2f}")
print(f"📈 Average SSIM: {avg_ssim:.4f}")

# Step 14: Helper function for loading & preprocessing image (used in inference)
def load_and_preprocess_image(path):
    img = Image.open(path).convert('RGB')
    img = transforms.Resize(image_size)(img)
    img = transforms.ToTensor()(img)
    return img

import torch.nn.functional as F
import torchvision.transforms.functional as TF
import matplotlib.pyplot as plt
import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
from torchvision.transforms import GaussianBlur

def apply_edge_enhancement(tensor_img, amount=1.5, radius=1, saturation_scale=1.2):
    """
    在 LAB 空间对亮度进行锐化，增强颜色对比。
    tensor_img: 输入 Tensor (3, H, W)，范围[0,1]
    amount: 锐化强度
    radius: 高斯模糊半径
    saturation_scale: 饱和度放大倍数
    """

    # Tensor -> PIL -> NumPy RGB
    img_np = TF.to_pil_image(tensor_img)
    img_rgb = np.array(img_np)

    # 转到 BGR (OpenCV 默认)
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

    # 转 LAB
    img_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB).astype(np.float32)

    # L 通道锐化（Unsharp Mask）
    L = img_lab[:, :, 0]
    blurred = cv2.GaussianBlur(L, (2 * radius + 1, 2 * radius + 1), 0)
    L_sharp = cv2.addWeighted(L, 1 + amount, blurred, -amount, 0)
    L_sharp = np.clip(L_sharp, 0, 255)

    img_lab[:, :, 0] = L_sharp

    # 饱和度增强 (a,b通道)
    a = img_lab[:, :, 1] - 128
    b = img_lab[:, :, 2] - 128

    a = np.clip(a * saturation_scale, -128, 127)
    b = np.clip(b * saturation_scale, -128, 127)

    img_lab[:, :, 1] = a + 128
    img_lab[:, :, 2] = b + 128

    # LAB -> BGR -> RGB
    img_bgr = cv2.cvtColor(img_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

    # 转回 Tensor
    enhanced_tensor = TF.to_tensor(img_rgb).to(tensor_img.device).clamp(0, 1)

    return enhanced_tensor


def interpolate_and_evaluate_full6(im_paths, gt_path, model):
    # 1. 讀取六張影像並轉成 Tensor
    frames = [load_and_preprocess_image(p) for p in im_paths]

    # 2. Optical Flow：使用 im3 和 im5
    img3 = cv2.imread(im_paths[2])
    img5 = cv2.imread(im_paths[3])
    if img3 is None or img5 is None:
        raise ValueError("❌ im3 或 im5 讀取失敗")

    flow = compute_flow(img3, img5)
    flow_x = flow[..., 0] / (flow.shape[1] - 1)
    flow_y = flow[..., 1] / (flow.shape[0] - 1)
    flow_norm = np.stack([flow_x, flow_y], axis=-1)
    flow_resized = cv2.resize(flow_norm, (448, 256), interpolation=cv2.INTER_LINEAR)
    flow_tensor = torch.tensor(flow_resized).permute(2, 0, 1).float()

    # 3. 模型輸入
    input_tensor = torch.cat(frames + [flow_tensor], dim=0).unsqueeze(0).to(device)  # (1, 20, 256, 448)

    # 4. Ground Truth，bicubic 插值到 2x 尺寸
    gt_tensor = load_and_preprocess_image(gt_path)
    gt_tensor = F.interpolate(gt_tensor.unsqueeze(0), scale_factor=2, mode='bicubic', align_corners=False)[0]  # ✅ modified

    # 5. 模型預測 + bicubic 插值
    model.eval()
    with torch.no_grad():
        output = model(input_tensor)  # (1, 3, 256, 448)
        output_upsampled = F.interpolate(output, scale_factor=2, mode='bicubic', align_corners=False)  # ✅ modified
        pred = output_upsampled[0].cpu()  # (3, 512, 896)

    # ✅ Edge Filtering 增強
    pred = apply_edge_enhancement(pred)  # ✅ added

    # 6. 殘差誤差圖
    residual = torch.abs(gt_tensor - pred).clamp(0, 1)

    # 7. 評估 PSNR / SSIM
    psnr = compute_psnr(pred, gt_tensor)
    ssim = compute_ssim(pred, gt_tensor)

    # 8. 顯示結果
    plt.figure(figsize=(15, 4))
    plt.subplot(1, 3, 1)
    plt.imshow(TF.to_pil_image(pred))
    plt.title("🔮 Interpolated + Edge Enhancement")
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(TF.to_pil_image(gt_tensor))
    plt.title("🎯 Ground Truth (Upsampled)")
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(TF.to_pil_image(residual))
    plt.title("📉 Residual")
    plt.axis('off')

    plt.show()

    print(f"📈 PSNR: {psnr:.2f}")
    print(f"📈 SSIM: {ssim:.4f}")

    return pred, psnr, ssim, residual

import os
from glob import glob

base_path = '/content/public_test_set/'

# 找出所有序列路径，例如 00071/0117
all_sequences = glob(os.path.join(base_path, '00071', '*'))

for seq_path in all_sequences:
    input_imgs = [os.path.join(seq_path, f'im{i}.png') for i in [1, 2, 3, 5, 6, 7]]
    gt_img = os.path.join(seq_path, 'im4.png')

    # 调用模型测试函数
    pred_frame, psnr, ssim, residual = interpolate_and_evaluate_full6(input_imgs, gt_img, model)

    print(f"結果 - 序列: {seq_path}")
    print(f"PSNR: {psnr:.2f}, SSIM: {ssim:.4f}")