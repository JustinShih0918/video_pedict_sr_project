{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a294dcb8",
   "metadata": {},
   "source": [
    "# 安裝必要套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcb96a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision matplotlib\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cb42c",
   "metadata": {},
   "source": [
    "# 上傳並解壓縮資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292f0ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"請上傳包含 High_Resolution / Low_Resolution 資料夾的 zip 檔案\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "zip_path = list(uploaded.keys())[0]\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\")\n",
    "\n",
    "print(\"解壓縮完成，開始讀取資料\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e3919",
   "metadata": {},
   "source": [
    "# 建立 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13291eca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SRDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.hr_root = os.path.join(root_dir, \"train\", \"High_Resolution\")\n",
    "        self.lr_root = os.path.join(root_dir, \"train\", \"Low_Resolution\")\n",
    "        self.transform = T.ToTensor()\n",
    "\n",
    "        # 遞迴找出所有 low-resolution 圖片\n",
    "        self.lr_paths = []\n",
    "        for root, _, files in os.walk(self.lr_root):\n",
    "            for file in files:\n",
    "                if file.endswith(\".png\"):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    self.lr_paths.append(full_path)\n",
    "\n",
    "        # 依照路徑排序確保對齊（重要）\n",
    "        self.lr_paths.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_path = self.lr_paths[idx]\n",
    "        # 取得相對路徑以定位對應 HR 檔案\n",
    "        rel_path = os.path.relpath(lr_path, self.lr_root)\n",
    "        hr_path = os.path.join(self.hr_root, rel_path)\n",
    "\n",
    "        # 載入圖片\n",
    "        lr_img = Image.open(lr_path).convert(\"RGB\")\n",
    "        hr_img = Image.open(hr_path).convert(\"RGB\")\n",
    "\n",
    "        return self.transform(lr_img), self.transform(hr_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e9fc2",
   "metadata": {},
   "source": [
    "# 定義 Upsampler CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec24b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CNNUpsampler(nn.Module):\n",
    "    def __init__(self, scale=2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 3 * scale * scale, 3, padding=1),\n",
    "            nn.PixelShuffle(scale)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed470ea4",
   "metadata": {},
   "source": [
    "# 設定訓練參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a77426",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = SRDataset(\"dataset\")\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "model = CNNUpsampler(scale=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "epochs = 30\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e94f41",
   "metadata": {},
   "source": [
    "# 開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e2eee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68bce74",
   "metadata": {},
   "source": [
    "# 視覺化 Loss 曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7de7f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"L1 Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a1ef7",
   "metadata": {},
   "source": [
    "# 儲存模型並下載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e7000",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"upsampler.pth\")\n",
    "print(\"✅ 模型儲存為 upsampler.pth\")\n",
    "\n",
    "files.download(\"upsampler.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
