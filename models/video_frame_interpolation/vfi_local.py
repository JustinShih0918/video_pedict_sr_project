# -*- coding: utf-8 -*-
"""vfi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iK4ZQD6RUmu7qHFqtoHR0BAkfDn3dlWG
"""

# ✅ Step 1: Mount Google Drive
# from google.colab import drive
# drive.mount('/content/drive')

import zipfile
import os
import glob
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
import cv2
import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF

# ✅ Step 2: Unzip the dataset

zip_path     = r"C:\NTHU\Sophomore_II\multi_media\topic4_release.zip"
extract_path = r"C:\NTHU\Sophomore_II\multi_media"

if not os.path.exists(os.path.join(extract_path, 'topic4_release')):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

# ✅ Step 3: Collect im1, im2, im3 from both High_Resolution and Low_Resolution
from tqdm import tqdm


def collect_paths_v2(res_type='High_Resolution'):
    base_path = os.path.join(r"C:\NTHU\Sophomore_II\multi_media\topic4_release\train", res_type)
    video_folders = sorted(glob.glob(os.path.join(base_path, '*', '*')))
    print(video_folders)
    path_list = []

    for folder in video_folders:
        frame_paths = [os.path.join(folder, f'im{i}.png') for i in range(1, 8)]
        if not all(os.path.exists(p) for p in frame_paths):
            continue

        # 指定前面 1,2,3 和後面 5,6,7 當作輸入，第四張當 GT
        inputs = [frame_paths[i] for i in (0,1,2,4,5,6)]   # im1,im2,im3,im5,im6,im7
        gt     = frame_paths[3]                             # im4
        path_list.append((inputs, gt))
    return path_list

# ✅ Step 4: Install dependencies
# !pip install torch torchvision

# ✅ Step 5: Optical flow function using OpenCV
def compute_flow(f0, f1):
    gray0 = cv2.cvtColor(f0, cv2.COLOR_BGR2GRAY)
    gray1 = cv2.cvtColor(f1, cv2.COLOR_BGR2GRAY)
    flow = cv2.calcOpticalFlowFarneback(gray0, gray1, None,
                                        0.5, 3, 15, 3, 5, 1.2, 0)
    return flow

# ✅ Step 6: Prepare dataset with flow + augmentation
import torch
from torch.utils.data import Dataset

image_size = (256, 448)

class InterpolationDatasetWithFlowCache(Dataset):
    def __init__(self, cached_list):
      self.cached = cached_list
      self.H, self.W = image_size[0], image_size[1]
      self.transform = transforms.Compose([
        transforms.Resize((self.H, self.W)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])
      ])

    def __len__(self):
        return len(self.cached)

    def __getitem__(self, idx):
        inputs_paths, gt_path, flow_path = self.cached[idx]

        # 1. 讀 6 張影格
        frames = []
        for p in inputs_paths:
            img = Image.open(p).convert('RGB')
            frames.append(self.transform(img))  # shape (3,256,256)

        # 2. 讀 flow
        flow = np.load(flow_path)
        flow_x = flow[...,0] / (flow.shape[1] - 1)
        flow_y = flow[...,1] / (flow.shape[0] - 1)
        flow_norm = np.stack([flow_x, flow_y], axis=-1)
        flow_resized = cv2.resize(flow_norm, (self.W, self.H), interpolation=cv2.INTER_LINEAR)
        flow_tensor = torch.from_numpy(flow_resized).permute(2,0,1).float()


        # 3. 拼接：6×3 + 2 = 20 通道
        input_tensor = torch.cat(frames + [flow_tensor], dim=0)  # (20,256,256)

        # 4. 讀 GT
        gt = Image.open(gt_path).convert('RGB')
        gt = transforms.Resize((self.H, self.W))(gt)
        gt = transforms.ToTensor()(gt)
        return input_tensor, gt

import os
import numpy as np

flow_cache_dir = '/content/flow_cache_updated'
os.makedirs(flow_cache_dir, exist_ok=True)

def preprocess_and_cache_flow(path_list):
    cached = []
    for inputs, gt_path in tqdm(path_list):
        im3_path, im5_path = inputs[2], inputs[3]
        # 建立 flow filename
        name3 = os.path.splitext(os.path.basename(im3_path))[0]
        name5 = os.path.splitext(os.path.basename(im5_path))[0]
        flow_file = os.path.join(
            flow_cache_dir,
            f"{name3}_{name5}.npy"
        )

        if not os.path.exists(flow_file):
            img3 = cv2.imread(im3_path)
            img5 = cv2.imread(im5_path)
            if img3 is None or img5 is None:
                continue
            flow = compute_flow(img3, img5)
            np.save(flow_file, flow)

        cached.append((inputs, gt_path, flow_file))
    return cached

from torch.utils.data import DataLoader
if __name__ == '__main__':
    # 準備資料路徑清單
    # 先收集前 500 筆
    high_paths = collect_paths_v2('High_Resolution')[:2000]
    low_paths = collect_paths_v2('Low_Resolution')[:2000]
    all_paths = high_paths + low_paths


    # 預處理光流並快取路徑
    cached_triplets = preprocess_and_cache_flow(all_paths)

    # 建立 Dataset 與 Dataloader
    dataset = InterpolationDatasetWithFlowCache(cached_triplets)
    dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)

    import torch

    print("CUDA 可用：", torch.cuda.is_available())
    print("GPU 名稱：", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "None")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    import torch.nn as nn

    class SimpleInterpNet(nn.Module):
        def __init__(self, in_ch=20, mid_ch=8):
            super().__init__()
            # 1x1 projection to reduce channels
            self.proj = nn.Conv2d(in_ch, mid_ch, kernel_size=1, bias=False)
            self.encoder = nn.Sequential(
                nn.Conv2d(mid_ch, 32, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(32, 64, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(64, 128, 3, padding=1),
                nn.ReLU()
            )

            self.middle = nn.Sequential(
                nn.Conv2d(128, 128, 3, padding=1),
                nn.ReLU()
            )

            self.decoder = nn.Sequential(
                nn.Conv2d(128, 64, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(64, 32, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(32, 3, 3, padding=1),
                nn.Sigmoid()
            )

        def forward(self, x):
            x = self.proj(x)
            x = self.encoder(x)
            x = self.middle(x)
            x = self.decoder(x)
            return x

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SimpleInterpNet().to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    loss_fn = nn.L1Loss()

    # Training
    epochs = 20
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)
            preds = model(inputs)
            loss = loss_fn(preds, targets)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"Epoch {epoch+1}/{epochs} - Loss: {total_loss / len(dataloader):.4f}")



    # 新增：建立存放插值影格的資料夾
    output_dir = r"C:\NTHU\Sophomore_II\multi_media\Final_project\video_pedict_sr_project\output"
    os.makedirs(output_dir, exist_ok=True)

    model.eval()
    with torch.no_grad():
        # 從 dataloader 取出第一批資料（8張）
        inputs, targets = next(iter(dataloader))
        inputs = inputs.to(device)

        preds = model(inputs)  # 預測插值影格

        for i in range(preds.size(0)):
            pred_img = preds[i].cpu()
            # Tensor 轉成 PIL Image
            pil_img = TF.to_pil_image(pred_img)

            # 顯示圖片（可選）
            plt.imshow(pil_img)
            plt.title(f'Interpolated Frame {i}')
            plt.axis('off')
            plt.show()

            # 存成 PNG 檔
            pil_img.save(f"{output_dir}/interp_{i}.png")

    import torch.nn.functional as F
    from skimage.metrics import structural_similarity as ssim_func
    from skimage.metrics import peak_signal_noise_ratio as psnr_func

    def compute_ssim(img1, img2):
        # Input: torch tensors (C, H, W)
        img1_np = img1.permute(1, 2, 0).cpu().numpy()
        img2_np = img2.permute(1, 2, 0).cpu().numpy()
        return ssim_func(img1_np, img2_np, data_range=1.0, channel_axis=2)

    def compute_psnr(img1, img2):
        img1_np = img1.permute(1, 2, 0).cpu().numpy()
        img2_np = img2.permute(1, 2, 0).cpu().numpy()
        return psnr_func(img1_np, img2_np, data_range=1.0)

    # 推論 + 評估
    model.eval()
    ssim_scores = []
    psnr_scores = []

    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs = inputs.to(device)
            targets = targets.to(device)

            preds = model(inputs)

            for pred, gt in zip(preds, targets):
                psnr = compute_psnr(pred, gt)
                ssim = compute_ssim(pred, gt)
                psnr_scores.append(psnr)
                ssim_scores.append(ssim)

    avg_psnr = sum(psnr_scores) / len(psnr_scores)
    avg_ssim = sum(ssim_scores) / len(ssim_scores)

    print(f"\n✅ Evaluation Finished:")
    print(f"📈 Average PSNR: {avg_psnr:.2f}")
    print(f"📈 Average SSIM: {avg_ssim:.4f}")
    '''
    def interpolate_and_evaluate(frame0_path, frame1_path, frame2_path, model):
        # 1. 讀圖
        f0_img_cv2 = cv2.imread(frame0_path)
        f2_img_cv2 = cv2.imread(frame2_path)
        if f0_img_cv2 is None or f2_img_cv2 is None:
            raise ValueError("⚠️ 讀取 frame0 或 frame2 失敗")

        # 2. 計算 Optical Flow
        flow = compute_flow(f0_img_cv2, f2_img_cv2)
        flow_resized = cv2.resize(flow, (256, 256), interpolation=cv2.INTER_LINEAR)
        flow_tensor = torch.tensor(flow_resized).permute(2, 0, 1).float() / 255.0

        # 3. 預處理 f0 和 f2
        f0_tensor = load_and_preprocess_image(frame0_path)
        f2_tensor = load_and_preprocess_image(frame2_path)

        # 4. 組成模型輸入
        input_tensor = torch.cat([f0_tensor, f2_tensor, flow_tensor], dim=0).unsqueeze(0).to(device)

        # 5. 預測插值影格
        model.eval()
        with torch.no_grad():
            pred = model(input_tensor)[0].cpu()  # shape: (3, 256, 256)

        # 6. 預處理 ground truth
        gt_tensor = load_and_preprocess_image(frame1_path)

        # 7. 計算 Residual（差異）
        residual = torch.abs(gt_tensor - pred).clamp(0, 1)  # 絕對差 + 限制範圍在 [0,1]

        # 8. 計算 PSNR & SSIM
        psnr = compute_psnr(pred, gt_tensor)
        ssim = compute_ssim(pred, gt_tensor)

        # 9. 顯示三張圖：預測、GT、Residual
        plt.figure(figsize=(15, 4))
        plt.subplot(1, 3, 1)
        plt.imshow(TF.to_pil_image(pred))
        plt.title("🔮 Interpolated Frame")
        plt.axis('off')

        plt.subplot(1, 3, 2)
        plt.imshow(TF.to_pil_image(gt_tensor))
        plt.title("🎯 Ground Truth (Frame1)")
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.imshow(TF.to_pil_image(residual))
        plt.title("📉 Residual (|GT - Pred|)")
        plt.axis('off')

        plt.show()

        print(f"📈 PSNR: {psnr:.2f}")
        print(f"📈 SSIM: {ssim:.4f}")

        return pred, psnr, ssim, residual

    # 輸入你的三張圖片路徑
    frame0_path = '/content/public_test_set/00071/0117/im1.png'
    frame1_path = '/content/public_test_set/00071/0117/im2.png'  # ground truth
    frame2_path = '/content/public_test_set/00071/0117/im3.png'

    # 呼叫函式
    pred_frame, psnr, ssim, residual = interpolate_and_evaluate(
        frame0_path, frame1_path, frame2_path, model
    )
    '''