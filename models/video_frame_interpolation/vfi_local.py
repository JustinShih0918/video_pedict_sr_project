# -*- coding: utf-8 -*-
"""vfi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iK4ZQD6RUmu7qHFqtoHR0BAkfDn3dlWG
"""

# âœ… Step 1: Mount Google Drive
# from google.colab import drive
# drive.mount('/content/drive')

import zipfile
import os
import glob
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
import cv2
import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF

# âœ… Step 2: Unzip the dataset

zip_path     = r"C:\NTHU\Sophomore_II\multi_media\topic4_release.zip"
extract_path = r"C:\NTHU\Sophomore_II\multi_media"

if not os.path.exists(os.path.join(extract_path, 'topic4_release')):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

# âœ… Step 3: Collect im1, im2, im3 from both High_Resolution and Low_Resolution
from tqdm import tqdm


def collect_paths_v2(res_type='High_Resolution'):
    base_path = os.path.join(r"C:\NTHU\Sophomore_II\multi_media\topic4_release\train", res_type)
    video_folders = sorted(glob.glob(os.path.join(base_path, '*', '*')))
    print(video_folders)
    path_list = []

    for folder in video_folders:
        frame_paths = [os.path.join(folder, f'im{i}.png') for i in range(1, 8)]
        if not all(os.path.exists(p) for p in frame_paths):
            continue

        # æŒ‡å®šå‰é¢ 1,2,3 å’Œå¾Œé¢ 5,6,7 ç•¶ä½œè¼¸å…¥ï¼Œç¬¬å››å¼µç•¶ GT
        inputs = [frame_paths[i] for i in (0,1,2,4,5,6)]   # im1,im2,im3,im5,im6,im7
        gt     = frame_paths[3]                             # im4
        path_list.append((inputs, gt))
    return path_list

# âœ… Step 4: Install dependencies
# !pip install torch torchvision

# âœ… Step 5: Optical flow function using OpenCV
def compute_flow(f0, f1):
    gray0 = cv2.cvtColor(f0, cv2.COLOR_BGR2GRAY)
    gray1 = cv2.cvtColor(f1, cv2.COLOR_BGR2GRAY)
    flow = cv2.calcOpticalFlowFarneback(gray0, gray1, None,
                                        0.5, 3, 15, 3, 5, 1.2, 0)
    return flow

# âœ… Step 6: Prepare dataset with flow + augmentation
import torch
from torch.utils.data import Dataset

image_size = (256, 448)

class InterpolationDatasetWithFlowCache(Dataset):
    def __init__(self, cached_list):
      self.cached = cached_list
      self.H, self.W = image_size[0], image_size[1]
      self.transform = transforms.Compose([
        transforms.Resize((self.H, self.W)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])
      ])

    def __len__(self):
        return len(self.cached)

    def __getitem__(self, idx):
        inputs_paths, gt_path, flow_path = self.cached[idx]

        # 1. è®€ 6 å¼µå½±æ ¼
        frames = []
        for p in inputs_paths:
            img = Image.open(p).convert('RGB')
            frames.append(self.transform(img))  # shape (3,256,256)

        # 2. è®€ flow
        flow = np.load(flow_path)
        flow_x = flow[...,0] / (flow.shape[1] - 1)
        flow_y = flow[...,1] / (flow.shape[0] - 1)
        flow_norm = np.stack([flow_x, flow_y], axis=-1)
        flow_resized = cv2.resize(flow_norm, (self.W, self.H), interpolation=cv2.INTER_LINEAR)
        flow_tensor = torch.from_numpy(flow_resized).permute(2,0,1).float()


        # 3. æ‹¼æ¥ï¼š6Ã—3 + 2 = 20 é€šé“
        input_tensor = torch.cat(frames + [flow_tensor], dim=0)  # (20,256,256)

        # 4. è®€ GT
        gt = Image.open(gt_path).convert('RGB')
        gt = transforms.Resize((self.H, self.W))(gt)
        gt = transforms.ToTensor()(gt)
        return input_tensor, gt

import os
import numpy as np

flow_cache_dir = '/content/flow_cache_updated'
os.makedirs(flow_cache_dir, exist_ok=True)

def preprocess_and_cache_flow(path_list):
    cached = []
    for inputs, gt_path in tqdm(path_list):
        im3_path, im5_path = inputs[2], inputs[3]
        # å»ºç«‹ flow filename
        name3 = os.path.splitext(os.path.basename(im3_path))[0]
        name5 = os.path.splitext(os.path.basename(im5_path))[0]
        flow_file = os.path.join(
            flow_cache_dir,
            f"{name3}_{name5}.npy"
        )

        if not os.path.exists(flow_file):
            img3 = cv2.imread(im3_path)
            img5 = cv2.imread(im5_path)
            if img3 is None or img5 is None:
                continue
            flow = compute_flow(img3, img5)
            np.save(flow_file, flow)

        cached.append((inputs, gt_path, flow_file))
    return cached

from torch.utils.data import DataLoader
if __name__ == '__main__':
    # æº–å‚™è³‡æ–™è·¯å¾‘æ¸…å–®
    # å…ˆæ”¶é›†å‰ 500 ç­†
    high_paths = collect_paths_v2('High_Resolution')[:2000]
    low_paths = collect_paths_v2('Low_Resolution')[:2000]
    all_paths = high_paths + low_paths


    # é è™•ç†å…‰æµä¸¦å¿«å–è·¯å¾‘
    cached_triplets = preprocess_and_cache_flow(all_paths)

    # å»ºç«‹ Dataset èˆ‡ Dataloader
    dataset = InterpolationDatasetWithFlowCache(cached_triplets)
    dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)

    import torch

    print("CUDA å¯ç”¨ï¼š", torch.cuda.is_available())
    print("GPU åç¨±ï¼š", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "None")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    import torch.nn as nn

    class SimpleInterpNet(nn.Module):
        def __init__(self, in_ch=20, mid_ch=8):
            super().__init__()
            # 1x1 projection to reduce channels
            self.proj = nn.Conv2d(in_ch, mid_ch, kernel_size=1, bias=False)
            self.encoder = nn.Sequential(
                nn.Conv2d(mid_ch, 32, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(32, 64, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(64, 128, 3, padding=1),
                nn.ReLU()
            )

            self.middle = nn.Sequential(
                nn.Conv2d(128, 128, 3, padding=1),
                nn.ReLU()
            )

            self.decoder = nn.Sequential(
                nn.Conv2d(128, 64, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(64, 32, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(32, 3, 3, padding=1),
                nn.Sigmoid()
            )

        def forward(self, x):
            x = self.proj(x)
            x = self.encoder(x)
            x = self.middle(x)
            x = self.decoder(x)
            return x

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SimpleInterpNet().to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    loss_fn = nn.L1Loss()

    # Training
    epochs = 20
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)
            preds = model(inputs)
            loss = loss_fn(preds, targets)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"Epoch {epoch+1}/{epochs} - Loss: {total_loss / len(dataloader):.4f}")



    # æ–°å¢ï¼šå»ºç«‹å­˜æ”¾æ’å€¼å½±æ ¼çš„è³‡æ–™å¤¾
    output_dir = r"C:\NTHU\Sophomore_II\multi_media\Final_project\video_pedict_sr_project\output"
    os.makedirs(output_dir, exist_ok=True)

    model.eval()
    with torch.no_grad():
        # å¾ dataloader å–å‡ºç¬¬ä¸€æ‰¹è³‡æ–™ï¼ˆ8å¼µï¼‰
        inputs, targets = next(iter(dataloader))
        inputs = inputs.to(device)

        preds = model(inputs)  # é æ¸¬æ’å€¼å½±æ ¼

        for i in range(preds.size(0)):
            pred_img = preds[i].cpu()
            # Tensor è½‰æˆ PIL Image
            pil_img = TF.to_pil_image(pred_img)

            # é¡¯ç¤ºåœ–ç‰‡ï¼ˆå¯é¸ï¼‰
            plt.imshow(pil_img)
            plt.title(f'Interpolated Frame {i}')
            plt.axis('off')
            plt.show()

            # å­˜æˆ PNG æª”
            pil_img.save(f"{output_dir}/interp_{i}.png")

    import torch.nn.functional as F
    from skimage.metrics import structural_similarity as ssim_func
    from skimage.metrics import peak_signal_noise_ratio as psnr_func

    def compute_ssim(img1, img2):
        # Input: torch tensors (C, H, W)
        img1_np = img1.permute(1, 2, 0).cpu().numpy()
        img2_np = img2.permute(1, 2, 0).cpu().numpy()
        return ssim_func(img1_np, img2_np, data_range=1.0, channel_axis=2)

    def compute_psnr(img1, img2):
        img1_np = img1.permute(1, 2, 0).cpu().numpy()
        img2_np = img2.permute(1, 2, 0).cpu().numpy()
        return psnr_func(img1_np, img2_np, data_range=1.0)

    # æ¨è«– + è©•ä¼°
    model.eval()
    ssim_scores = []
    psnr_scores = []

    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs = inputs.to(device)
            targets = targets.to(device)

            preds = model(inputs)

            for pred, gt in zip(preds, targets):
                psnr = compute_psnr(pred, gt)
                ssim = compute_ssim(pred, gt)
                psnr_scores.append(psnr)
                ssim_scores.append(ssim)

    avg_psnr = sum(psnr_scores) / len(psnr_scores)
    avg_ssim = sum(ssim_scores) / len(ssim_scores)

    print(f"\nâœ… Evaluation Finished:")
    print(f"ğŸ“ˆ Average PSNR: {avg_psnr:.2f}")
    print(f"ğŸ“ˆ Average SSIM: {avg_ssim:.4f}")
    '''
    def interpolate_and_evaluate(frame0_path, frame1_path, frame2_path, model):
        # 1. è®€åœ–
        f0_img_cv2 = cv2.imread(frame0_path)
        f2_img_cv2 = cv2.imread(frame2_path)
        if f0_img_cv2 is None or f2_img_cv2 is None:
            raise ValueError("âš ï¸ è®€å– frame0 æˆ– frame2 å¤±æ•—")

        # 2. è¨ˆç®— Optical Flow
        flow = compute_flow(f0_img_cv2, f2_img_cv2)
        flow_resized = cv2.resize(flow, (256, 256), interpolation=cv2.INTER_LINEAR)
        flow_tensor = torch.tensor(flow_resized).permute(2, 0, 1).float() / 255.0

        # 3. é è™•ç† f0 å’Œ f2
        f0_tensor = load_and_preprocess_image(frame0_path)
        f2_tensor = load_and_preprocess_image(frame2_path)

        # 4. çµ„æˆæ¨¡å‹è¼¸å…¥
        input_tensor = torch.cat([f0_tensor, f2_tensor, flow_tensor], dim=0).unsqueeze(0).to(device)

        # 5. é æ¸¬æ’å€¼å½±æ ¼
        model.eval()
        with torch.no_grad():
            pred = model(input_tensor)[0].cpu()  # shape: (3, 256, 256)

        # 6. é è™•ç† ground truth
        gt_tensor = load_and_preprocess_image(frame1_path)

        # 7. è¨ˆç®— Residualï¼ˆå·®ç•°ï¼‰
        residual = torch.abs(gt_tensor - pred).clamp(0, 1)  # çµ•å°å·® + é™åˆ¶ç¯„åœåœ¨ [0,1]

        # 8. è¨ˆç®— PSNR & SSIM
        psnr = compute_psnr(pred, gt_tensor)
        ssim = compute_ssim(pred, gt_tensor)

        # 9. é¡¯ç¤ºä¸‰å¼µåœ–ï¼šé æ¸¬ã€GTã€Residual
        plt.figure(figsize=(15, 4))
        plt.subplot(1, 3, 1)
        plt.imshow(TF.to_pil_image(pred))
        plt.title("ğŸ”® Interpolated Frame")
        plt.axis('off')

        plt.subplot(1, 3, 2)
        plt.imshow(TF.to_pil_image(gt_tensor))
        plt.title("ğŸ¯ Ground Truth (Frame1)")
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.imshow(TF.to_pil_image(residual))
        plt.title("ğŸ“‰ Residual (|GT - Pred|)")
        plt.axis('off')

        plt.show()

        print(f"ğŸ“ˆ PSNR: {psnr:.2f}")
        print(f"ğŸ“ˆ SSIM: {ssim:.4f}")

        return pred, psnr, ssim, residual

    # è¼¸å…¥ä½ çš„ä¸‰å¼µåœ–ç‰‡è·¯å¾‘
    frame0_path = '/content/public_test_set/00071/0117/im1.png'
    frame1_path = '/content/public_test_set/00071/0117/im2.png'  # ground truth
    frame2_path = '/content/public_test_set/00071/0117/im3.png'

    # å‘¼å«å‡½å¼
    pred_frame, psnr, ssim, residual = interpolate_and_evaluate(
        frame0_path, frame1_path, frame2_path, model
    )
    '''